Last week was a tough one for our small group of IFPRI researchers in Accra. On Tuesday, we delivered a message to one of our partner organizations there that its project to promote integrated soil fertility management (ISFM) to Ghanaian smallholders did not yield any measurable impacts during the course of our two-year evaluation. Farmers were no more likely to know about, understand or apply ISFM as a result of the project, plain and simple. But it’s never so simple, is it? Maybe the project did have sizable impacts. Our implementing partners had to make a few course corrections during the project to reach the number of farmers they had originally targeted. Unfortunately, that correction disrupted our evaluation design. In effect, we were measuring outcomes in a sample of farmers that was no longer representative of the population served by the project. So we just couldn’t detect any impacts even if they did occur. That’s life in the impact evaluation world. Many of our colleagues already know this, but it’s worth repeating—again and again—to be better aware of the potential for such situations and to learn how to avoid them in the future. That is what we did after delivering our disappointing message. Then we discussed our experience further with colleagues from ISSER, IPA, UDS, CABI, IFDC, AGRA and IITA at a learning event in Accra on April 25. We used this occasion to review our approaches to project implementation and impact evaluation, focusing our attention on how agricultural extension services can be leveraged to promote natural resource management (NRM) practices and principles to Ghanaian smallholders. NRM is complicated: It encompasses a range of knowledge-intensive and site-specific management principles combined with a broad array of modern inputs and technologies. When applied successfully, good NRM principles and practices can improve and sustain the productive use of land, soil, water and biodiversity for present and future generations. Programming and evaluating in the NRM space can be extremely complex. Here are a few thoughts, gleaned from our discussions, on how to deal with that complexity. A negative evaluation is often an implementer’s worst-case scenario. It may give a government or donor a reason to pull project funding. But a good evaluator can help cushion the blow by highlighting lessons learned, encouraging innovation and opening opportunities for further evaluation. The reality is that many implementers are too afraid to experiment or too afraid to subject their experiments to rigorous evaluations. But learning from failures is as important as learning from success, as the growing popularity of fail festivals suggests. By David J. Spielman, Kwaw Andam and Simrin Makhija David J. Spielman is a Senior Research Fellow with IFPRI's Environment and Production Technology Division (EPTD). Kwaw Andam is a Research Fellow with IFPRI's Ghana Strategy Support Program. Simrin Makhija is an EPTD Research Analyst. The post first appeared on IFPRI’s website here. The learning event in Accra was organized by IFPRI and its partners in Ghana. The event was generously supported by the International Initiative for Impact Evaluation (3ie); the U.S. Agency for International Development (USAID) Feed the Future Developing Local Extension Capacity (DLEC) project, led by Digital Green; the CGIAR Research Program on Policies, Institutions and Markets (PIM); and the Alliance for a Green Revolution in Africa (AGRA).